{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN(PyTorch) - Iris flower dataset\n",
    "* Project: To classify Iris flowers\n",
    "* Project Scope: Create, train and validate Neural Network on Iris flower dataset\n",
    "* Data source: [Iris Data Set to download](https://archive.ics.uci.edu/ml/datasets/iris)\n",
    "* About data: The dataset contains 3 classes (Iris Setosa, Iris Versicolour, Iris Virginica) of 50 instances each, where each class refers to a type of iris plant. \n",
    "* Author: Shashi Kiran Chilukuri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Analysis Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch Packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import get_data, Netwrok classes\n",
    "import Iris_model\n",
    "import data\n",
    "\n",
    "# Load data\n",
    "dataset = pd.read_csv('iris.data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets analyze and visualize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length_cm    150 non-null float64\n",
      "sepal_width_cm     150 non-null float64\n",
      "petal_length_cm    150 non-null float64\n",
      "petal_width_cm     150 non-null float64\n",
      "class              150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see there are 5 Columns and its datatypes:\n",
    "* Out of 5 columns, 4 are input variables/features (X), 1 output /target variable (y) \n",
    "* There are 150 rows/training examples (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_cm</th>\n",
       "      <th>sepal_width_cm</th>\n",
       "      <th>petal_length_cm</th>\n",
       "      <th>petal_width_cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n",
       "0              5.1             3.5              1.4             0.2   \n",
       "1              4.9             3.0              1.4             0.2   \n",
       "2              4.7             3.2              1.3             0.2   \n",
       "3              4.6             3.1              1.5             0.2   \n",
       "4              5.0             3.6              1.4             0.2   \n",
       "\n",
       "         class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice, we have numeric data in our inputs and flower name in the class column. We need to convert this class column so that our neural network can understand. But before that lets analyze further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length_cm    0\n",
       "sepal_width_cm     0\n",
       "petal_length_cm    0\n",
       "petal_width_cm     0\n",
       "class              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null columns\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont have any null data in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHRCAYAAACIOGpaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt3/MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bf260053c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correlation between features\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(dataset.corr(),annot=True,cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-virginica     50\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice there are 3 iris flower types and each one got 50 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating train and test loader\n",
    "train_loader = torch.utils.data.DataLoader(data.get_data('iris.data.csv','train'), \n",
    "                                           batch_size=60, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(data.get_data('iris.data.csv', ' '), \n",
    "                                           batch_size=60, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Creating instance of the model #####\n",
    "model = Iris_model.Network(4, 3, [100,50])\n",
    "##### Loss Function #######################\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "##### Optimizer ###########################\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, nesterov=True, momentum=0.9, dampening=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/500..  Train Loss: 1.972..  Test Loss: 1.186..  Test Accuracy: 30.000\n",
      "Epoch: 2/500..  Train Loss: 2.135..  Test Loss: 1.148..  Test Accuracy: 30.000\n",
      "Epoch: 3/500..  Train Loss: 2.130..  Test Loss: 1.113..  Test Accuracy: 46.667\n",
      "Epoch: 4/500..  Train Loss: 2.068..  Test Loss: 1.085..  Test Accuracy: 30.000\n",
      "Epoch: 5/500..  Train Loss: 1.990..  Test Loss: 1.062..  Test Accuracy: 30.000\n",
      "Epoch: 6/500..  Train Loss: 2.005..  Test Loss: 1.043..  Test Accuracy: 30.000\n",
      "Epoch: 7/500..  Train Loss: 1.947..  Test Loss: 1.026..  Test Accuracy: 30.000\n",
      "Epoch: 8/500..  Train Loss: 2.008..  Test Loss: 1.011..  Test Accuracy: 30.000\n",
      "Epoch: 9/500..  Train Loss: 2.015..  Test Loss: 0.998..  Test Accuracy: 30.000\n",
      "Epoch: 10/500..  Train Loss: 1.987..  Test Loss: 0.986..  Test Accuracy: 33.333\n",
      "Epoch: 11/500..  Train Loss: 1.929..  Test Loss: 0.974..  Test Accuracy: 60.000\n",
      "Epoch: 12/500..  Train Loss: 1.901..  Test Loss: 0.964..  Test Accuracy: 70.000\n",
      "Epoch: 13/500..  Train Loss: 1.946..  Test Loss: 0.954..  Test Accuracy: 70.000\n",
      "Epoch: 14/500..  Train Loss: 1.903..  Test Loss: 0.945..  Test Accuracy: 70.000\n",
      "Epoch: 15/500..  Train Loss: 1.899..  Test Loss: 0.936..  Test Accuracy: 70.000\n",
      "Epoch: 16/500..  Train Loss: 1.844..  Test Loss: 0.926..  Test Accuracy: 70.000\n",
      "Epoch: 17/500..  Train Loss: 1.846..  Test Loss: 0.917..  Test Accuracy: 70.000\n",
      "Epoch: 18/500..  Train Loss: 1.810..  Test Loss: 0.908..  Test Accuracy: 70.000\n",
      "Epoch: 19/500..  Train Loss: 1.787..  Test Loss: 0.898..  Test Accuracy: 70.000\n",
      "Epoch: 20/500..  Train Loss: 1.771..  Test Loss: 0.887..  Test Accuracy: 70.000\n",
      "Epoch: 21/500..  Train Loss: 1.763..  Test Loss: 0.877..  Test Accuracy: 70.000\n",
      "Epoch: 22/500..  Train Loss: 1.728..  Test Loss: 0.866..  Test Accuracy: 70.000\n",
      "Epoch: 23/500..  Train Loss: 1.729..  Test Loss: 0.855..  Test Accuracy: 70.000\n",
      "Epoch: 24/500..  Train Loss: 1.723..  Test Loss: 0.843..  Test Accuracy: 70.000\n",
      "Epoch: 25/500..  Train Loss: 1.687..  Test Loss: 0.832..  Test Accuracy: 70.000\n",
      "Epoch: 26/500..  Train Loss: 1.672..  Test Loss: 0.820..  Test Accuracy: 70.000\n",
      "Epoch: 27/500..  Train Loss: 1.630..  Test Loss: 0.809..  Test Accuracy: 70.000\n",
      "Epoch: 28/500..  Train Loss: 1.616..  Test Loss: 0.797..  Test Accuracy: 70.000\n",
      "Epoch: 29/500..  Train Loss: 1.612..  Test Loss: 0.786..  Test Accuracy: 70.000\n",
      "Epoch: 30/500..  Train Loss: 1.587..  Test Loss: 0.774..  Test Accuracy: 70.000\n",
      "Epoch: 31/500..  Train Loss: 1.530..  Test Loss: 0.762..  Test Accuracy: 70.000\n",
      "Epoch: 32/500..  Train Loss: 1.551..  Test Loss: 0.751..  Test Accuracy: 70.000\n",
      "Epoch: 33/500..  Train Loss: 1.573..  Test Loss: 0.740..  Test Accuracy: 70.000\n",
      "Epoch: 34/500..  Train Loss: 1.486..  Test Loss: 0.728..  Test Accuracy: 70.000\n",
      "Epoch: 35/500..  Train Loss: 1.494..  Test Loss: 0.717..  Test Accuracy: 70.000\n",
      "Epoch: 36/500..  Train Loss: 1.442..  Test Loss: 0.706..  Test Accuracy: 70.000\n",
      "Epoch: 37/500..  Train Loss: 1.461..  Test Loss: 0.695..  Test Accuracy: 70.000\n",
      "Epoch: 38/500..  Train Loss: 1.406..  Test Loss: 0.685..  Test Accuracy: 70.000\n",
      "Epoch: 39/500..  Train Loss: 1.436..  Test Loss: 0.674..  Test Accuracy: 70.000\n",
      "Epoch: 40/500..  Train Loss: 1.410..  Test Loss: 0.664..  Test Accuracy: 70.000\n",
      "Epoch: 41/500..  Train Loss: 1.385..  Test Loss: 0.653..  Test Accuracy: 70.000\n",
      "Epoch: 42/500..  Train Loss: 1.377..  Test Loss: 0.643..  Test Accuracy: 70.000\n",
      "Epoch: 43/500..  Train Loss: 1.320..  Test Loss: 0.633..  Test Accuracy: 73.333\n",
      "Epoch: 44/500..  Train Loss: 1.303..  Test Loss: 0.624..  Test Accuracy: 73.333\n",
      "Epoch: 45/500..  Train Loss: 1.306..  Test Loss: 0.614..  Test Accuracy: 73.333\n",
      "Epoch: 46/500..  Train Loss: 1.292..  Test Loss: 0.605..  Test Accuracy: 73.333\n",
      "Epoch: 47/500..  Train Loss: 1.215..  Test Loss: 0.596..  Test Accuracy: 73.333\n",
      "Epoch: 48/500..  Train Loss: 1.277..  Test Loss: 0.588..  Test Accuracy: 73.333\n",
      "Epoch: 49/500..  Train Loss: 1.244..  Test Loss: 0.579..  Test Accuracy: 73.333\n",
      "Epoch: 50/500..  Train Loss: 1.183..  Test Loss: 0.571..  Test Accuracy: 73.333\n",
      "Epoch: 51/500..  Train Loss: 1.212..  Test Loss: 0.563..  Test Accuracy: 73.333\n",
      "Epoch: 52/500..  Train Loss: 1.136..  Test Loss: 0.556..  Test Accuracy: 73.333\n",
      "Epoch: 53/500..  Train Loss: 1.191..  Test Loss: 0.548..  Test Accuracy: 73.333\n",
      "Epoch: 54/500..  Train Loss: 1.162..  Test Loss: 0.541..  Test Accuracy: 73.333\n",
      "Epoch: 55/500..  Train Loss: 1.085..  Test Loss: 0.534..  Test Accuracy: 76.667\n",
      "Epoch: 56/500..  Train Loss: 1.107..  Test Loss: 0.527..  Test Accuracy: 80.000\n",
      "Epoch: 57/500..  Train Loss: 1.095..  Test Loss: 0.521..  Test Accuracy: 80.000\n",
      "Epoch: 58/500..  Train Loss: 1.115..  Test Loss: 0.515..  Test Accuracy: 80.000\n",
      "Epoch: 59/500..  Train Loss: 1.090..  Test Loss: 0.509..  Test Accuracy: 80.000\n",
      "Epoch: 60/500..  Train Loss: 1.145..  Test Loss: 0.503..  Test Accuracy: 80.000\n",
      "Epoch: 61/500..  Train Loss: 1.030..  Test Loss: 0.498..  Test Accuracy: 80.000\n",
      "Epoch: 62/500..  Train Loss: 1.117..  Test Loss: 0.492..  Test Accuracy: 80.000\n",
      "Epoch: 63/500..  Train Loss: 1.120..  Test Loss: 0.487..  Test Accuracy: 80.000\n",
      "Epoch: 64/500..  Train Loss: 1.032..  Test Loss: 0.482..  Test Accuracy: 83.333\n",
      "Epoch: 65/500..  Train Loss: 1.143..  Test Loss: 0.477..  Test Accuracy: 83.333\n",
      "Epoch: 66/500..  Train Loss: 0.972..  Test Loss: 0.473..  Test Accuracy: 83.333\n",
      "Epoch: 67/500..  Train Loss: 1.023..  Test Loss: 0.468..  Test Accuracy: 83.333\n",
      "Epoch: 68/500..  Train Loss: 0.982..  Test Loss: 0.464..  Test Accuracy: 86.667\n",
      "Epoch: 69/500..  Train Loss: 1.043..  Test Loss: 0.460..  Test Accuracy: 86.667\n",
      "Epoch: 70/500..  Train Loss: 0.988..  Test Loss: 0.456..  Test Accuracy: 86.667\n",
      "Epoch: 71/500..  Train Loss: 1.057..  Test Loss: 0.451..  Test Accuracy: 86.667\n",
      "Epoch: 72/500..  Train Loss: 1.020..  Test Loss: 0.448..  Test Accuracy: 86.667\n",
      "Epoch: 73/500..  Train Loss: 0.959..  Test Loss: 0.444..  Test Accuracy: 86.667\n",
      "Epoch: 74/500..  Train Loss: 0.848..  Test Loss: 0.440..  Test Accuracy: 90.000\n",
      "Epoch: 75/500..  Train Loss: 0.963..  Test Loss: 0.437..  Test Accuracy: 90.000\n",
      "Epoch: 76/500..  Train Loss: 0.937..  Test Loss: 0.433..  Test Accuracy: 90.000\n",
      "Epoch: 77/500..  Train Loss: 0.940..  Test Loss: 0.430..  Test Accuracy: 90.000\n",
      "Epoch: 78/500..  Train Loss: 0.976..  Test Loss: 0.427..  Test Accuracy: 90.000\n",
      "Epoch: 79/500..  Train Loss: 0.947..  Test Loss: 0.424..  Test Accuracy: 90.000\n",
      "Epoch: 80/500..  Train Loss: 0.860..  Test Loss: 0.421..  Test Accuracy: 90.000\n",
      "Epoch: 81/500..  Train Loss: 0.862..  Test Loss: 0.418..  Test Accuracy: 90.000\n",
      "Epoch: 82/500..  Train Loss: 0.890..  Test Loss: 0.415..  Test Accuracy: 90.000\n",
      "Epoch: 83/500..  Train Loss: 0.838..  Test Loss: 0.412..  Test Accuracy: 90.000\n",
      "Epoch: 84/500..  Train Loss: 0.905..  Test Loss: 0.409..  Test Accuracy: 90.000\n",
      "Epoch: 85/500..  Train Loss: 0.909..  Test Loss: 0.407..  Test Accuracy: 90.000\n",
      "Epoch: 86/500..  Train Loss: 0.954..  Test Loss: 0.404..  Test Accuracy: 90.000\n",
      "Epoch: 87/500..  Train Loss: 0.886..  Test Loss: 0.401..  Test Accuracy: 90.000\n",
      "Epoch: 88/500..  Train Loss: 0.873..  Test Loss: 0.399..  Test Accuracy: 90.000\n",
      "Epoch: 89/500..  Train Loss: 0.901..  Test Loss: 0.396..  Test Accuracy: 90.000\n",
      "Epoch: 90/500..  Train Loss: 0.805..  Test Loss: 0.394..  Test Accuracy: 90.000\n",
      "Epoch: 91/500..  Train Loss: 0.868..  Test Loss: 0.391..  Test Accuracy: 93.333\n",
      "Epoch: 92/500..  Train Loss: 0.846..  Test Loss: 0.389..  Test Accuracy: 93.333\n",
      "Epoch: 93/500..  Train Loss: 0.873..  Test Loss: 0.387..  Test Accuracy: 93.333\n",
      "Epoch: 94/500..  Train Loss: 0.883..  Test Loss: 0.384..  Test Accuracy: 93.333\n",
      "Epoch: 95/500..  Train Loss: 0.850..  Test Loss: 0.382..  Test Accuracy: 93.333\n",
      "Epoch: 96/500..  Train Loss: 0.947..  Test Loss: 0.380..  Test Accuracy: 93.333\n",
      "Epoch: 97/500..  Train Loss: 0.836..  Test Loss: 0.377..  Test Accuracy: 93.333\n",
      "Epoch: 98/500..  Train Loss: 0.884..  Test Loss: 0.375..  Test Accuracy: 93.333\n",
      "Epoch: 99/500..  Train Loss: 0.852..  Test Loss: 0.373..  Test Accuracy: 93.333\n",
      "Epoch: 100/500..  Train Loss: 0.826..  Test Loss: 0.371..  Test Accuracy: 93.333\n",
      "Epoch: 101/500..  Train Loss: 0.901..  Test Loss: 0.369..  Test Accuracy: 93.333\n",
      "Epoch: 102/500..  Train Loss: 0.798..  Test Loss: 0.367..  Test Accuracy: 93.333\n",
      "Epoch: 103/500..  Train Loss: 0.744..  Test Loss: 0.364..  Test Accuracy: 96.667\n",
      "Epoch: 104/500..  Train Loss: 0.682..  Test Loss: 0.362..  Test Accuracy: 96.667\n",
      "Epoch: 105/500..  Train Loss: 0.838..  Test Loss: 0.360..  Test Accuracy: 96.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106/500..  Train Loss: 0.837..  Test Loss: 0.358..  Test Accuracy: 96.667\n",
      "Epoch: 107/500..  Train Loss: 0.859..  Test Loss: 0.356..  Test Accuracy: 96.667\n",
      "Epoch: 108/500..  Train Loss: 0.880..  Test Loss: 0.354..  Test Accuracy: 96.667\n",
      "Epoch: 109/500..  Train Loss: 0.794..  Test Loss: 0.353..  Test Accuracy: 96.667\n",
      "Epoch: 110/500..  Train Loss: 0.841..  Test Loss: 0.350..  Test Accuracy: 96.667\n",
      "Epoch: 111/500..  Train Loss: 0.724..  Test Loss: 0.348..  Test Accuracy: 96.667\n",
      "Epoch: 112/500..  Train Loss: 0.683..  Test Loss: 0.346..  Test Accuracy: 96.667\n",
      "Epoch: 113/500..  Train Loss: 0.756..  Test Loss: 0.344..  Test Accuracy: 96.667\n",
      "Epoch: 114/500..  Train Loss: 0.656..  Test Loss: 0.343..  Test Accuracy: 96.667\n",
      "Epoch: 115/500..  Train Loss: 0.780..  Test Loss: 0.341..  Test Accuracy: 96.667\n",
      "Epoch: 116/500..  Train Loss: 0.738..  Test Loss: 0.339..  Test Accuracy: 96.667\n",
      "Epoch: 117/500..  Train Loss: 0.761..  Test Loss: 0.337..  Test Accuracy: 96.667\n",
      "Epoch: 118/500..  Train Loss: 0.743..  Test Loss: 0.335..  Test Accuracy: 96.667\n",
      "Epoch: 119/500..  Train Loss: 0.772..  Test Loss: 0.333..  Test Accuracy: 96.667\n",
      "Epoch: 120/500..  Train Loss: 0.795..  Test Loss: 0.331..  Test Accuracy: 96.667\n",
      "Epoch: 121/500..  Train Loss: 0.681..  Test Loss: 0.329..  Test Accuracy: 96.667\n",
      "Epoch: 122/500..  Train Loss: 0.689..  Test Loss: 0.327..  Test Accuracy: 96.667\n",
      "Epoch: 123/500..  Train Loss: 0.571..  Test Loss: 0.325..  Test Accuracy: 96.667\n",
      "Epoch: 124/500..  Train Loss: 0.735..  Test Loss: 0.323..  Test Accuracy: 96.667\n",
      "Epoch: 125/500..  Train Loss: 0.723..  Test Loss: 0.321..  Test Accuracy: 96.667\n",
      "Epoch: 126/500..  Train Loss: 0.735..  Test Loss: 0.320..  Test Accuracy: 96.667\n",
      "Epoch: 127/500..  Train Loss: 0.772..  Test Loss: 0.318..  Test Accuracy: 96.667\n",
      "Epoch: 128/500..  Train Loss: 0.754..  Test Loss: 0.316..  Test Accuracy: 96.667\n",
      "Epoch: 129/500..  Train Loss: 0.739..  Test Loss: 0.314..  Test Accuracy: 96.667\n",
      "Epoch: 130/500..  Train Loss: 0.704..  Test Loss: 0.312..  Test Accuracy: 96.667\n",
      "Epoch: 131/500..  Train Loss: 0.608..  Test Loss: 0.310..  Test Accuracy: 96.667\n",
      "Epoch: 132/500..  Train Loss: 0.671..  Test Loss: 0.309..  Test Accuracy: 96.667\n",
      "Epoch: 133/500..  Train Loss: 0.692..  Test Loss: 0.307..  Test Accuracy: 96.667\n",
      "Epoch: 134/500..  Train Loss: 0.703..  Test Loss: 0.305..  Test Accuracy: 96.667\n",
      "Epoch: 135/500..  Train Loss: 0.559..  Test Loss: 0.303..  Test Accuracy: 96.667\n",
      "Epoch: 136/500..  Train Loss: 0.643..  Test Loss: 0.301..  Test Accuracy: 96.667\n",
      "Epoch: 137/500..  Train Loss: 0.617..  Test Loss: 0.299..  Test Accuracy: 96.667\n",
      "Epoch: 138/500..  Train Loss: 0.565..  Test Loss: 0.297..  Test Accuracy: 96.667\n",
      "Epoch: 139/500..  Train Loss: 0.628..  Test Loss: 0.296..  Test Accuracy: 96.667\n",
      "Epoch: 140/500..  Train Loss: 0.661..  Test Loss: 0.294..  Test Accuracy: 96.667\n",
      "Epoch: 141/500..  Train Loss: 0.664..  Test Loss: 0.292..  Test Accuracy: 96.667\n",
      "Epoch: 142/500..  Train Loss: 0.613..  Test Loss: 0.290..  Test Accuracy: 96.667\n",
      "Epoch: 143/500..  Train Loss: 0.622..  Test Loss: 0.288..  Test Accuracy: 96.667\n",
      "Epoch: 144/500..  Train Loss: 0.630..  Test Loss: 0.287..  Test Accuracy: 96.667\n",
      "Epoch: 145/500..  Train Loss: 0.653..  Test Loss: 0.285..  Test Accuracy: 96.667\n",
      "Epoch: 146/500..  Train Loss: 0.575..  Test Loss: 0.283..  Test Accuracy: 96.667\n",
      "Epoch: 147/500..  Train Loss: 0.661..  Test Loss: 0.282..  Test Accuracy: 96.667\n",
      "Epoch: 148/500..  Train Loss: 0.678..  Test Loss: 0.280..  Test Accuracy: 96.667\n",
      "Epoch: 149/500..  Train Loss: 0.620..  Test Loss: 0.278..  Test Accuracy: 96.667\n",
      "Epoch: 150/500..  Train Loss: 0.667..  Test Loss: 0.277..  Test Accuracy: 100.000\n",
      "Epoch: 151/500..  Train Loss: 0.549..  Test Loss: 0.275..  Test Accuracy: 100.000\n",
      "Epoch: 152/500..  Train Loss: 0.584..  Test Loss: 0.273..  Test Accuracy: 100.000\n",
      "Epoch: 153/500..  Train Loss: 0.583..  Test Loss: 0.272..  Test Accuracy: 100.000\n",
      "Epoch: 154/500..  Train Loss: 0.584..  Test Loss: 0.270..  Test Accuracy: 100.000\n",
      "Epoch: 155/500..  Train Loss: 0.560..  Test Loss: 0.269..  Test Accuracy: 100.000\n",
      "Epoch: 156/500..  Train Loss: 0.578..  Test Loss: 0.267..  Test Accuracy: 100.000\n",
      "Epoch: 157/500..  Train Loss: 0.601..  Test Loss: 0.265..  Test Accuracy: 100.000\n",
      "Epoch: 158/500..  Train Loss: 0.608..  Test Loss: 0.263..  Test Accuracy: 96.667\n",
      "Epoch: 159/500..  Train Loss: 0.610..  Test Loss: 0.262..  Test Accuracy: 96.667\n",
      "Epoch: 160/500..  Train Loss: 0.527..  Test Loss: 0.260..  Test Accuracy: 100.000\n",
      "Epoch: 161/500..  Train Loss: 0.535..  Test Loss: 0.259..  Test Accuracy: 100.000\n",
      "Epoch: 162/500..  Train Loss: 0.584..  Test Loss: 0.258..  Test Accuracy: 100.000\n",
      "Epoch: 163/500..  Train Loss: 0.563..  Test Loss: 0.256..  Test Accuracy: 100.000\n",
      "Epoch: 164/500..  Train Loss: 0.509..  Test Loss: 0.254..  Test Accuracy: 100.000\n",
      "Epoch: 165/500..  Train Loss: 0.579..  Test Loss: 0.253..  Test Accuracy: 100.000\n",
      "Epoch: 166/500..  Train Loss: 0.538..  Test Loss: 0.251..  Test Accuracy: 100.000\n",
      "Epoch: 167/500..  Train Loss: 0.581..  Test Loss: 0.250..  Test Accuracy: 100.000\n",
      "Epoch: 168/500..  Train Loss: 0.560..  Test Loss: 0.248..  Test Accuracy: 100.000\n",
      "Epoch: 169/500..  Train Loss: 0.420..  Test Loss: 0.247..  Test Accuracy: 100.000\n",
      "Epoch: 170/500..  Train Loss: 0.505..  Test Loss: 0.245..  Test Accuracy: 100.000\n",
      "Epoch: 171/500..  Train Loss: 0.477..  Test Loss: 0.244..  Test Accuracy: 100.000\n",
      "Epoch: 172/500..  Train Loss: 0.585..  Test Loss: 0.242..  Test Accuracy: 100.000\n",
      "Epoch: 173/500..  Train Loss: 0.538..  Test Loss: 0.241..  Test Accuracy: 100.000\n",
      "Epoch: 174/500..  Train Loss: 0.538..  Test Loss: 0.239..  Test Accuracy: 100.000\n",
      "Epoch: 175/500..  Train Loss: 0.551..  Test Loss: 0.238..  Test Accuracy: 100.000\n",
      "Epoch: 176/500..  Train Loss: 0.426..  Test Loss: 0.237..  Test Accuracy: 100.000\n",
      "Epoch: 177/500..  Train Loss: 0.480..  Test Loss: 0.235..  Test Accuracy: 100.000\n",
      "Epoch: 178/500..  Train Loss: 0.480..  Test Loss: 0.234..  Test Accuracy: 100.000\n",
      "Epoch: 179/500..  Train Loss: 0.542..  Test Loss: 0.233..  Test Accuracy: 100.000\n",
      "Epoch: 180/500..  Train Loss: 0.503..  Test Loss: 0.231..  Test Accuracy: 100.000\n",
      "Epoch: 181/500..  Train Loss: 0.496..  Test Loss: 0.230..  Test Accuracy: 100.000\n",
      "Epoch: 182/500..  Train Loss: 0.476..  Test Loss: 0.228..  Test Accuracy: 100.000\n",
      "Epoch: 183/500..  Train Loss: 0.477..  Test Loss: 0.226..  Test Accuracy: 100.000\n",
      "Epoch: 184/500..  Train Loss: 0.581..  Test Loss: 0.225..  Test Accuracy: 100.000\n",
      "Epoch: 185/500..  Train Loss: 0.514..  Test Loss: 0.224..  Test Accuracy: 100.000\n",
      "Epoch: 186/500..  Train Loss: 0.463..  Test Loss: 0.222..  Test Accuracy: 100.000\n",
      "Epoch: 187/500..  Train Loss: 0.462..  Test Loss: 0.221..  Test Accuracy: 100.000\n",
      "Epoch: 188/500..  Train Loss: 0.454..  Test Loss: 0.220..  Test Accuracy: 100.000\n",
      "Epoch: 189/500..  Train Loss: 0.464..  Test Loss: 0.219..  Test Accuracy: 100.000\n",
      "Epoch: 190/500..  Train Loss: 0.424..  Test Loss: 0.217..  Test Accuracy: 100.000\n",
      "Epoch: 191/500..  Train Loss: 0.427..  Test Loss: 0.216..  Test Accuracy: 100.000\n",
      "Epoch: 192/500..  Train Loss: 0.436..  Test Loss: 0.214..  Test Accuracy: 100.000\n",
      "Epoch: 193/500..  Train Loss: 0.525..  Test Loss: 0.213..  Test Accuracy: 100.000\n",
      "Epoch: 194/500..  Train Loss: 0.412..  Test Loss: 0.212..  Test Accuracy: 100.000\n",
      "Epoch: 195/500..  Train Loss: 0.448..  Test Loss: 0.211..  Test Accuracy: 100.000\n",
      "Epoch: 196/500..  Train Loss: 0.440..  Test Loss: 0.210..  Test Accuracy: 100.000\n",
      "Epoch: 197/500..  Train Loss: 0.403..  Test Loss: 0.209..  Test Accuracy: 100.000\n",
      "Epoch: 198/500..  Train Loss: 0.421..  Test Loss: 0.207..  Test Accuracy: 100.000\n",
      "Epoch: 199/500..  Train Loss: 0.490..  Test Loss: 0.206..  Test Accuracy: 100.000\n",
      "Epoch: 200/500..  Train Loss: 0.425..  Test Loss: 0.205..  Test Accuracy: 100.000\n",
      "Epoch: 201/500..  Train Loss: 0.428..  Test Loss: 0.204..  Test Accuracy: 100.000\n",
      "Epoch: 202/500..  Train Loss: 0.404..  Test Loss: 0.203..  Test Accuracy: 100.000\n",
      "Epoch: 203/500..  Train Loss: 0.460..  Test Loss: 0.202..  Test Accuracy: 100.000\n",
      "Epoch: 204/500..  Train Loss: 0.393..  Test Loss: 0.201..  Test Accuracy: 100.000\n",
      "Epoch: 205/500..  Train Loss: 0.432..  Test Loss: 0.200..  Test Accuracy: 100.000\n",
      "Epoch: 206/500..  Train Loss: 0.382..  Test Loss: 0.199..  Test Accuracy: 100.000\n",
      "Epoch: 207/500..  Train Loss: 0.339..  Test Loss: 0.197..  Test Accuracy: 100.000\n",
      "Epoch: 208/500..  Train Loss: 0.359..  Test Loss: 0.196..  Test Accuracy: 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 209/500..  Train Loss: 0.481..  Test Loss: 0.195..  Test Accuracy: 100.000\n",
      "Epoch: 210/500..  Train Loss: 0.390..  Test Loss: 0.194..  Test Accuracy: 100.000\n",
      "Epoch: 211/500..  Train Loss: 0.404..  Test Loss: 0.193..  Test Accuracy: 100.000\n",
      "Epoch: 212/500..  Train Loss: 0.366..  Test Loss: 0.192..  Test Accuracy: 100.000\n",
      "Epoch: 213/500..  Train Loss: 0.431..  Test Loss: 0.191..  Test Accuracy: 100.000\n",
      "Epoch: 214/500..  Train Loss: 0.427..  Test Loss: 0.190..  Test Accuracy: 100.000\n",
      "Epoch: 215/500..  Train Loss: 0.405..  Test Loss: 0.190..  Test Accuracy: 100.000\n",
      "Epoch: 216/500..  Train Loss: 0.428..  Test Loss: 0.188..  Test Accuracy: 100.000\n",
      "Epoch: 217/500..  Train Loss: 0.346..  Test Loss: 0.187..  Test Accuracy: 100.000\n",
      "Epoch: 218/500..  Train Loss: 0.331..  Test Loss: 0.186..  Test Accuracy: 100.000\n",
      "Epoch: 219/500..  Train Loss: 0.342..  Test Loss: 0.186..  Test Accuracy: 100.000\n",
      "Epoch: 220/500..  Train Loss: 0.417..  Test Loss: 0.185..  Test Accuracy: 100.000\n",
      "Epoch: 221/500..  Train Loss: 0.390..  Test Loss: 0.184..  Test Accuracy: 100.000\n",
      "Epoch: 222/500..  Train Loss: 0.407..  Test Loss: 0.183..  Test Accuracy: 100.000\n",
      "Epoch: 223/500..  Train Loss: 0.394..  Test Loss: 0.182..  Test Accuracy: 100.000\n",
      "Epoch: 224/500..  Train Loss: 0.376..  Test Loss: 0.181..  Test Accuracy: 100.000\n",
      "Epoch: 225/500..  Train Loss: 0.359..  Test Loss: 0.180..  Test Accuracy: 100.000\n",
      "Epoch: 226/500..  Train Loss: 0.323..  Test Loss: 0.179..  Test Accuracy: 100.000\n",
      "Epoch: 227/500..  Train Loss: 0.374..  Test Loss: 0.178..  Test Accuracy: 100.000\n",
      "Epoch: 228/500..  Train Loss: 0.356..  Test Loss: 0.178..  Test Accuracy: 100.000\n",
      "Epoch: 229/500..  Train Loss: 0.395..  Test Loss: 0.177..  Test Accuracy: 100.000\n",
      "Epoch: 230/500..  Train Loss: 0.355..  Test Loss: 0.177..  Test Accuracy: 100.000\n",
      "Epoch: 231/500..  Train Loss: 0.372..  Test Loss: 0.176..  Test Accuracy: 100.000\n",
      "Epoch: 232/500..  Train Loss: 0.379..  Test Loss: 0.174..  Test Accuracy: 100.000\n",
      "Epoch: 233/500..  Train Loss: 0.310..  Test Loss: 0.174..  Test Accuracy: 100.000\n",
      "Epoch: 234/500..  Train Loss: 0.373..  Test Loss: 0.172..  Test Accuracy: 100.000\n",
      "Epoch: 235/500..  Train Loss: 0.385..  Test Loss: 0.172..  Test Accuracy: 100.000\n",
      "Epoch: 236/500..  Train Loss: 0.369..  Test Loss: 0.171..  Test Accuracy: 100.000\n",
      "Epoch: 237/500..  Train Loss: 0.364..  Test Loss: 0.170..  Test Accuracy: 100.000\n",
      "Epoch: 238/500..  Train Loss: 0.351..  Test Loss: 0.170..  Test Accuracy: 100.000\n",
      "Epoch: 239/500..  Train Loss: 0.313..  Test Loss: 0.169..  Test Accuracy: 100.000\n",
      "Epoch: 240/500..  Train Loss: 0.305..  Test Loss: 0.168..  Test Accuracy: 100.000\n",
      "Epoch: 241/500..  Train Loss: 0.340..  Test Loss: 0.167..  Test Accuracy: 100.000\n",
      "Epoch: 242/500..  Train Loss: 0.377..  Test Loss: 0.167..  Test Accuracy: 100.000\n",
      "Epoch: 243/500..  Train Loss: 0.331..  Test Loss: 0.166..  Test Accuracy: 100.000\n",
      "Epoch: 244/500..  Train Loss: 0.358..  Test Loss: 0.165..  Test Accuracy: 100.000\n",
      "Epoch: 245/500..  Train Loss: 0.297..  Test Loss: 0.164..  Test Accuracy: 100.000\n",
      "Epoch: 246/500..  Train Loss: 0.343..  Test Loss: 0.163..  Test Accuracy: 100.000\n",
      "Epoch: 247/500..  Train Loss: 0.283..  Test Loss: 0.163..  Test Accuracy: 100.000\n",
      "Epoch: 248/500..  Train Loss: 0.291..  Test Loss: 0.162..  Test Accuracy: 100.000\n",
      "Epoch: 249/500..  Train Loss: 0.310..  Test Loss: 0.161..  Test Accuracy: 100.000\n",
      "Epoch: 250/500..  Train Loss: 0.343..  Test Loss: 0.161..  Test Accuracy: 100.000\n",
      "Epoch: 251/500..  Train Loss: 0.259..  Test Loss: 0.160..  Test Accuracy: 100.000\n",
      "Epoch: 252/500..  Train Loss: 0.330..  Test Loss: 0.159..  Test Accuracy: 100.000\n",
      "Epoch: 253/500..  Train Loss: 0.261..  Test Loss: 0.159..  Test Accuracy: 100.000\n",
      "Epoch: 254/500..  Train Loss: 0.366..  Test Loss: 0.158..  Test Accuracy: 100.000\n",
      "Epoch: 255/500..  Train Loss: 0.312..  Test Loss: 0.157..  Test Accuracy: 100.000\n",
      "Epoch: 256/500..  Train Loss: 0.357..  Test Loss: 0.157..  Test Accuracy: 100.000\n",
      "Epoch: 257/500..  Train Loss: 0.248..  Test Loss: 0.156..  Test Accuracy: 100.000\n",
      "Epoch: 258/500..  Train Loss: 0.336..  Test Loss: 0.155..  Test Accuracy: 100.000\n",
      "Epoch: 259/500..  Train Loss: 0.348..  Test Loss: 0.154..  Test Accuracy: 100.000\n",
      "Epoch: 260/500..  Train Loss: 0.281..  Test Loss: 0.154..  Test Accuracy: 100.000\n",
      "Epoch: 261/500..  Train Loss: 0.329..  Test Loss: 0.154..  Test Accuracy: 100.000\n",
      "Epoch: 262/500..  Train Loss: 0.360..  Test Loss: 0.153..  Test Accuracy: 100.000\n",
      "Epoch: 263/500..  Train Loss: 0.316..  Test Loss: 0.152..  Test Accuracy: 100.000\n",
      "Epoch: 264/500..  Train Loss: 0.261..  Test Loss: 0.152..  Test Accuracy: 100.000\n",
      "Epoch: 265/500..  Train Loss: 0.333..  Test Loss: 0.151..  Test Accuracy: 100.000\n",
      "Epoch: 266/500..  Train Loss: 0.381..  Test Loss: 0.150..  Test Accuracy: 100.000\n",
      "Epoch: 267/500..  Train Loss: 0.238..  Test Loss: 0.150..  Test Accuracy: 100.000\n",
      "Epoch: 268/500..  Train Loss: 0.328..  Test Loss: 0.149..  Test Accuracy: 100.000\n",
      "Epoch: 269/500..  Train Loss: 0.321..  Test Loss: 0.149..  Test Accuracy: 100.000\n",
      "Epoch: 270/500..  Train Loss: 0.279..  Test Loss: 0.148..  Test Accuracy: 100.000\n",
      "Epoch: 271/500..  Train Loss: 0.272..  Test Loss: 0.147..  Test Accuracy: 100.000\n",
      "Epoch: 272/500..  Train Loss: 0.266..  Test Loss: 0.147..  Test Accuracy: 100.000\n",
      "Epoch: 273/500..  Train Loss: 0.233..  Test Loss: 0.146..  Test Accuracy: 100.000\n",
      "Epoch: 274/500..  Train Loss: 0.306..  Test Loss: 0.146..  Test Accuracy: 100.000\n",
      "Epoch: 275/500..  Train Loss: 0.281..  Test Loss: 0.145..  Test Accuracy: 100.000\n",
      "Epoch: 276/500..  Train Loss: 0.352..  Test Loss: 0.145..  Test Accuracy: 100.000\n",
      "Epoch: 277/500..  Train Loss: 0.268..  Test Loss: 0.145..  Test Accuracy: 100.000\n",
      "Epoch: 278/500..  Train Loss: 0.375..  Test Loss: 0.144..  Test Accuracy: 100.000\n",
      "Epoch: 279/500..  Train Loss: 0.274..  Test Loss: 0.144..  Test Accuracy: 100.000\n",
      "Epoch: 280/500..  Train Loss: 0.229..  Test Loss: 0.143..  Test Accuracy: 100.000\n",
      "Epoch: 281/500..  Train Loss: 0.240..  Test Loss: 0.142..  Test Accuracy: 100.000\n",
      "Epoch: 282/500..  Train Loss: 0.317..  Test Loss: 0.142..  Test Accuracy: 100.000\n",
      "Epoch: 283/500..  Train Loss: 0.301..  Test Loss: 0.141..  Test Accuracy: 100.000\n",
      "Epoch: 284/500..  Train Loss: 0.346..  Test Loss: 0.141..  Test Accuracy: 100.000\n",
      "Epoch: 285/500..  Train Loss: 0.282..  Test Loss: 0.140..  Test Accuracy: 100.000\n",
      "Epoch: 286/500..  Train Loss: 0.295..  Test Loss: 0.140..  Test Accuracy: 100.000\n",
      "Epoch: 287/500..  Train Loss: 0.280..  Test Loss: 0.140..  Test Accuracy: 100.000\n",
      "Epoch: 288/500..  Train Loss: 0.336..  Test Loss: 0.139..  Test Accuracy: 100.000\n",
      "Epoch: 289/500..  Train Loss: 0.268..  Test Loss: 0.138..  Test Accuracy: 100.000\n",
      "Epoch: 290/500..  Train Loss: 0.277..  Test Loss: 0.138..  Test Accuracy: 100.000\n",
      "Epoch: 291/500..  Train Loss: 0.291..  Test Loss: 0.138..  Test Accuracy: 100.000\n",
      "Epoch: 292/500..  Train Loss: 0.259..  Test Loss: 0.137..  Test Accuracy: 100.000\n",
      "Epoch: 293/500..  Train Loss: 0.252..  Test Loss: 0.136..  Test Accuracy: 100.000\n",
      "Epoch: 294/500..  Train Loss: 0.271..  Test Loss: 0.136..  Test Accuracy: 100.000\n",
      "Epoch: 295/500..  Train Loss: 0.343..  Test Loss: 0.135..  Test Accuracy: 100.000\n",
      "Epoch: 296/500..  Train Loss: 0.285..  Test Loss: 0.135..  Test Accuracy: 100.000\n",
      "Epoch: 297/500..  Train Loss: 0.275..  Test Loss: 0.135..  Test Accuracy: 100.000\n",
      "Epoch: 298/500..  Train Loss: 0.213..  Test Loss: 0.134..  Test Accuracy: 100.000\n",
      "Epoch: 299/500..  Train Loss: 0.240..  Test Loss: 0.134..  Test Accuracy: 100.000\n",
      "Epoch: 300/500..  Train Loss: 0.311..  Test Loss: 0.134..  Test Accuracy: 100.000\n",
      "Epoch: 301/500..  Train Loss: 0.224..  Test Loss: 0.133..  Test Accuracy: 100.000\n",
      "Epoch: 302/500..  Train Loss: 0.231..  Test Loss: 0.132..  Test Accuracy: 100.000\n",
      "Epoch: 303/500..  Train Loss: 0.327..  Test Loss: 0.132..  Test Accuracy: 100.000\n",
      "Epoch: 304/500..  Train Loss: 0.317..  Test Loss: 0.132..  Test Accuracy: 100.000\n",
      "Epoch: 305/500..  Train Loss: 0.324..  Test Loss: 0.131..  Test Accuracy: 100.000\n",
      "Epoch: 306/500..  Train Loss: 0.264..  Test Loss: 0.131..  Test Accuracy: 100.000\n",
      "Epoch: 307/500..  Train Loss: 0.246..  Test Loss: 0.131..  Test Accuracy: 100.000\n",
      "Epoch: 308/500..  Train Loss: 0.239..  Test Loss: 0.130..  Test Accuracy: 100.000\n",
      "Epoch: 309/500..  Train Loss: 0.220..  Test Loss: 0.130..  Test Accuracy: 100.000\n",
      "Epoch: 310/500..  Train Loss: 0.306..  Test Loss: 0.129..  Test Accuracy: 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 311/500..  Train Loss: 0.249..  Test Loss: 0.129..  Test Accuracy: 100.000\n",
      "Epoch: 312/500..  Train Loss: 0.242..  Test Loss: 0.129..  Test Accuracy: 100.000\n",
      "Epoch: 313/500..  Train Loss: 0.259..  Test Loss: 0.129..  Test Accuracy: 100.000\n",
      "Epoch: 314/500..  Train Loss: 0.223..  Test Loss: 0.128..  Test Accuracy: 100.000\n",
      "Epoch: 315/500..  Train Loss: 0.252..  Test Loss: 0.127..  Test Accuracy: 100.000\n",
      "Epoch: 316/500..  Train Loss: 0.263..  Test Loss: 0.127..  Test Accuracy: 100.000\n",
      "Epoch: 317/500..  Train Loss: 0.243..  Test Loss: 0.126..  Test Accuracy: 100.000\n",
      "Epoch: 318/500..  Train Loss: 0.270..  Test Loss: 0.126..  Test Accuracy: 100.000\n",
      "Epoch: 319/500..  Train Loss: 0.310..  Test Loss: 0.126..  Test Accuracy: 100.000\n",
      "Epoch: 320/500..  Train Loss: 0.222..  Test Loss: 0.126..  Test Accuracy: 100.000\n",
      "Epoch: 321/500..  Train Loss: 0.245..  Test Loss: 0.126..  Test Accuracy: 100.000\n",
      "Epoch: 322/500..  Train Loss: 0.252..  Test Loss: 0.125..  Test Accuracy: 100.000\n",
      "Epoch: 323/500..  Train Loss: 0.260..  Test Loss: 0.125..  Test Accuracy: 100.000\n",
      "Epoch: 324/500..  Train Loss: 0.250..  Test Loss: 0.124..  Test Accuracy: 100.000\n",
      "Epoch: 325/500..  Train Loss: 0.234..  Test Loss: 0.124..  Test Accuracy: 100.000\n",
      "Epoch: 326/500..  Train Loss: 0.217..  Test Loss: 0.123..  Test Accuracy: 100.000\n",
      "Epoch: 327/500..  Train Loss: 0.252..  Test Loss: 0.123..  Test Accuracy: 100.000\n",
      "Epoch: 328/500..  Train Loss: 0.283..  Test Loss: 0.123..  Test Accuracy: 100.000\n",
      "Epoch: 329/500..  Train Loss: 0.213..  Test Loss: 0.123..  Test Accuracy: 100.000\n",
      "Epoch: 330/500..  Train Loss: 0.211..  Test Loss: 0.123..  Test Accuracy: 100.000\n",
      "Epoch: 331/500..  Train Loss: 0.255..  Test Loss: 0.122..  Test Accuracy: 100.000\n",
      "Epoch: 332/500..  Train Loss: 0.225..  Test Loss: 0.121..  Test Accuracy: 100.000\n",
      "Epoch: 333/500..  Train Loss: 0.256..  Test Loss: 0.120..  Test Accuracy: 100.000\n",
      "Epoch: 334/500..  Train Loss: 0.289..  Test Loss: 0.120..  Test Accuracy: 100.000\n",
      "Epoch: 335/500..  Train Loss: 0.291..  Test Loss: 0.120..  Test Accuracy: 100.000\n",
      "Epoch: 336/500..  Train Loss: 0.246..  Test Loss: 0.121..  Test Accuracy: 100.000\n",
      "Epoch: 337/500..  Train Loss: 0.216..  Test Loss: 0.121..  Test Accuracy: 100.000\n",
      "Epoch: 338/500..  Train Loss: 0.245..  Test Loss: 0.120..  Test Accuracy: 100.000\n",
      "Epoch: 339/500..  Train Loss: 0.276..  Test Loss: 0.120..  Test Accuracy: 100.000\n",
      "Epoch: 340/500..  Train Loss: 0.194..  Test Loss: 0.120..  Test Accuracy: 100.000\n",
      "Epoch: 341/500..  Train Loss: 0.248..  Test Loss: 0.119..  Test Accuracy: 100.000\n",
      "Epoch: 342/500..  Train Loss: 0.235..  Test Loss: 0.118..  Test Accuracy: 100.000\n",
      "Epoch: 343/500..  Train Loss: 0.162..  Test Loss: 0.118..  Test Accuracy: 100.000\n",
      "Epoch: 344/500..  Train Loss: 0.241..  Test Loss: 0.117..  Test Accuracy: 100.000\n",
      "Epoch: 345/500..  Train Loss: 0.205..  Test Loss: 0.117..  Test Accuracy: 100.000\n",
      "Epoch: 346/500..  Train Loss: 0.251..  Test Loss: 0.117..  Test Accuracy: 100.000\n",
      "Epoch: 347/500..  Train Loss: 0.217..  Test Loss: 0.117..  Test Accuracy: 100.000\n",
      "Epoch: 348/500..  Train Loss: 0.225..  Test Loss: 0.117..  Test Accuracy: 100.000\n",
      "Epoch: 349/500..  Train Loss: 0.184..  Test Loss: 0.118..  Test Accuracy: 100.000\n",
      "Epoch: 350/500..  Train Loss: 0.282..  Test Loss: 0.117..  Test Accuracy: 100.000\n",
      "Epoch: 351/500..  Train Loss: 0.227..  Test Loss: 0.117..  Test Accuracy: 100.000\n",
      "Epoch: 352/500..  Train Loss: 0.210..  Test Loss: 0.116..  Test Accuracy: 100.000\n",
      "Epoch: 353/500..  Train Loss: 0.274..  Test Loss: 0.115..  Test Accuracy: 100.000\n",
      "Epoch: 354/500..  Train Loss: 0.282..  Test Loss: 0.114..  Test Accuracy: 100.000\n",
      "Epoch: 355/500..  Train Loss: 0.190..  Test Loss: 0.115..  Test Accuracy: 100.000\n",
      "Epoch: 356/500..  Train Loss: 0.268..  Test Loss: 0.114..  Test Accuracy: 100.000\n",
      "Epoch: 357/500..  Train Loss: 0.260..  Test Loss: 0.114..  Test Accuracy: 100.000\n",
      "Epoch: 358/500..  Train Loss: 0.255..  Test Loss: 0.115..  Test Accuracy: 100.000\n",
      "Epoch: 359/500..  Train Loss: 0.240..  Test Loss: 0.114..  Test Accuracy: 100.000\n",
      "Epoch: 360/500..  Train Loss: 0.190..  Test Loss: 0.114..  Test Accuracy: 100.000\n",
      "Epoch: 361/500..  Train Loss: 0.298..  Test Loss: 0.113..  Test Accuracy: 100.000\n",
      "Epoch: 362/500..  Train Loss: 0.265..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 363/500..  Train Loss: 0.196..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 364/500..  Train Loss: 0.261..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 365/500..  Train Loss: 0.234..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 366/500..  Train Loss: 0.175..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 367/500..  Train Loss: 0.219..  Test Loss: 0.111..  Test Accuracy: 100.000\n",
      "Epoch: 368/500..  Train Loss: 0.232..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 369/500..  Train Loss: 0.252..  Test Loss: 0.113..  Test Accuracy: 100.000\n",
      "Epoch: 370/500..  Train Loss: 0.182..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 371/500..  Train Loss: 0.239..  Test Loss: 0.112..  Test Accuracy: 100.000\n",
      "Epoch: 372/500..  Train Loss: 0.220..  Test Loss: 0.110..  Test Accuracy: 100.000\n",
      "Epoch: 373/500..  Train Loss: 0.164..  Test Loss: 0.110..  Test Accuracy: 100.000\n",
      "Epoch: 374/500..  Train Loss: 0.170..  Test Loss: 0.109..  Test Accuracy: 100.000\n",
      "Epoch: 375/500..  Train Loss: 0.199..  Test Loss: 0.109..  Test Accuracy: 100.000\n",
      "Epoch: 376/500..  Train Loss: 0.280..  Test Loss: 0.109..  Test Accuracy: 100.000\n",
      "Epoch: 377/500..  Train Loss: 0.177..  Test Loss: 0.110..  Test Accuracy: 100.000\n",
      "Epoch: 378/500..  Train Loss: 0.188..  Test Loss: 0.110..  Test Accuracy: 100.000\n",
      "Epoch: 379/500..  Train Loss: 0.219..  Test Loss: 0.109..  Test Accuracy: 100.000\n",
      "Epoch: 380/500..  Train Loss: 0.145..  Test Loss: 0.109..  Test Accuracy: 100.000\n",
      "Epoch: 381/500..  Train Loss: 0.218..  Test Loss: 0.109..  Test Accuracy: 100.000\n",
      "Epoch: 382/500..  Train Loss: 0.269..  Test Loss: 0.108..  Test Accuracy: 100.000\n",
      "Epoch: 383/500..  Train Loss: 0.221..  Test Loss: 0.108..  Test Accuracy: 100.000\n",
      "Epoch: 384/500..  Train Loss: 0.137..  Test Loss: 0.109..  Test Accuracy: 100.000\n",
      "Epoch: 385/500..  Train Loss: 0.226..  Test Loss: 0.108..  Test Accuracy: 100.000\n",
      "Epoch: 386/500..  Train Loss: 0.250..  Test Loss: 0.107..  Test Accuracy: 100.000\n",
      "Epoch: 387/500..  Train Loss: 0.235..  Test Loss: 0.108..  Test Accuracy: 100.000\n",
      "Epoch: 388/500..  Train Loss: 0.255..  Test Loss: 0.108..  Test Accuracy: 100.000\n",
      "Epoch: 389/500..  Train Loss: 0.186..  Test Loss: 0.107..  Test Accuracy: 100.000\n",
      "Epoch: 390/500..  Train Loss: 0.203..  Test Loss: 0.108..  Test Accuracy: 100.000\n",
      "Epoch: 391/500..  Train Loss: 0.185..  Test Loss: 0.107..  Test Accuracy: 100.000\n",
      "Epoch: 392/500..  Train Loss: 0.184..  Test Loss: 0.107..  Test Accuracy: 100.000\n",
      "Epoch: 393/500..  Train Loss: 0.168..  Test Loss: 0.106..  Test Accuracy: 100.000\n",
      "Epoch: 394/500..  Train Loss: 0.105..  Test Loss: 0.106..  Test Accuracy: 100.000\n",
      "Epoch: 395/500..  Train Loss: 0.256..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 396/500..  Train Loss: 0.167..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 397/500..  Train Loss: 0.248..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 398/500..  Train Loss: 0.176..  Test Loss: 0.106..  Test Accuracy: 100.000\n",
      "Epoch: 399/500..  Train Loss: 0.267..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 400/500..  Train Loss: 0.221..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 401/500..  Train Loss: 0.152..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 402/500..  Train Loss: 0.180..  Test Loss: 0.106..  Test Accuracy: 100.000\n",
      "Epoch: 403/500..  Train Loss: 0.248..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 404/500..  Train Loss: 0.165..  Test Loss: 0.105..  Test Accuracy: 100.000\n",
      "Epoch: 405/500..  Train Loss: 0.155..  Test Loss: 0.104..  Test Accuracy: 100.000\n",
      "Epoch: 406/500..  Train Loss: 0.210..  Test Loss: 0.104..  Test Accuracy: 100.000\n",
      "Epoch: 407/500..  Train Loss: 0.206..  Test Loss: 0.104..  Test Accuracy: 100.000\n",
      "Epoch: 408/500..  Train Loss: 0.229..  Test Loss: 0.104..  Test Accuracy: 100.000\n",
      "Epoch: 409/500..  Train Loss: 0.247..  Test Loss: 0.104..  Test Accuracy: 100.000\n",
      "Epoch: 410/500..  Train Loss: 0.179..  Test Loss: 0.104..  Test Accuracy: 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411/500..  Train Loss: 0.168..  Test Loss: 0.104..  Test Accuracy: 100.000\n",
      "Epoch: 412/500..  Train Loss: 0.256..  Test Loss: 0.104..  Test Accuracy: 100.000\n",
      "Epoch: 413/500..  Train Loss: 0.205..  Test Loss: 0.103..  Test Accuracy: 100.000\n",
      "Epoch: 414/500..  Train Loss: 0.223..  Test Loss: 0.103..  Test Accuracy: 100.000\n",
      "Epoch: 415/500..  Train Loss: 0.138..  Test Loss: 0.103..  Test Accuracy: 100.000\n",
      "Epoch: 416/500..  Train Loss: 0.231..  Test Loss: 0.102..  Test Accuracy: 100.000\n",
      "Epoch: 417/500..  Train Loss: 0.146..  Test Loss: 0.102..  Test Accuracy: 100.000\n",
      "Epoch: 418/500..  Train Loss: 0.137..  Test Loss: 0.102..  Test Accuracy: 100.000\n",
      "Epoch: 419/500..  Train Loss: 0.245..  Test Loss: 0.102..  Test Accuracy: 100.000\n",
      "Epoch: 420/500..  Train Loss: 0.207..  Test Loss: 0.102..  Test Accuracy: 100.000\n",
      "Epoch: 421/500..  Train Loss: 0.207..  Test Loss: 0.102..  Test Accuracy: 100.000\n",
      "Epoch: 422/500..  Train Loss: 0.131..  Test Loss: 0.102..  Test Accuracy: 100.000\n",
      "Epoch: 423/500..  Train Loss: 0.214..  Test Loss: 0.101..  Test Accuracy: 100.000\n",
      "Epoch: 424/500..  Train Loss: 0.180..  Test Loss: 0.101..  Test Accuracy: 100.000\n",
      "Epoch: 425/500..  Train Loss: 0.225..  Test Loss: 0.100..  Test Accuracy: 100.000\n",
      "Epoch: 426/500..  Train Loss: 0.136..  Test Loss: 0.101..  Test Accuracy: 100.000\n",
      "Epoch: 427/500..  Train Loss: 0.218..  Test Loss: 0.101..  Test Accuracy: 100.000\n",
      "Epoch: 428/500..  Train Loss: 0.205..  Test Loss: 0.101..  Test Accuracy: 100.000\n",
      "Epoch: 429/500..  Train Loss: 0.216..  Test Loss: 0.100..  Test Accuracy: 100.000\n",
      "Epoch: 430/500..  Train Loss: 0.215..  Test Loss: 0.100..  Test Accuracy: 100.000\n",
      "Epoch: 431/500..  Train Loss: 0.166..  Test Loss: 0.099..  Test Accuracy: 100.000\n",
      "Epoch: 432/500..  Train Loss: 0.234..  Test Loss: 0.099..  Test Accuracy: 100.000\n",
      "Epoch: 433/500..  Train Loss: 0.100..  Test Loss: 0.099..  Test Accuracy: 100.000\n",
      "Epoch: 434/500..  Train Loss: 0.202..  Test Loss: 0.099..  Test Accuracy: 100.000\n",
      "Epoch: 435/500..  Train Loss: 0.226..  Test Loss: 0.100..  Test Accuracy: 100.000\n",
      "Epoch: 436/500..  Train Loss: 0.180..  Test Loss: 0.100..  Test Accuracy: 100.000\n",
      "Epoch: 437/500..  Train Loss: 0.205..  Test Loss: 0.101..  Test Accuracy: 100.000\n",
      "Epoch: 438/500..  Train Loss: 0.219..  Test Loss: 0.099..  Test Accuracy: 100.000\n",
      "Epoch: 439/500..  Train Loss: 0.167..  Test Loss: 0.100..  Test Accuracy: 100.000\n",
      "Epoch: 440/500..  Train Loss: 0.237..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 441/500..  Train Loss: 0.201..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 442/500..  Train Loss: 0.170..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 443/500..  Train Loss: 0.203..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 444/500..  Train Loss: 0.204..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 445/500..  Train Loss: 0.213..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 446/500..  Train Loss: 0.185..  Test Loss: 0.099..  Test Accuracy: 100.000\n",
      "Epoch: 447/500..  Train Loss: 0.206..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 448/500..  Train Loss: 0.228..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 449/500..  Train Loss: 0.146..  Test Loss: 0.099..  Test Accuracy: 100.000\n",
      "Epoch: 450/500..  Train Loss: 0.223..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 451/500..  Train Loss: 0.135..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 452/500..  Train Loss: 0.160..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 453/500..  Train Loss: 0.142..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 454/500..  Train Loss: 0.207..  Test Loss: 0.097..  Test Accuracy: 100.000\n",
      "Epoch: 455/500..  Train Loss: 0.210..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 456/500..  Train Loss: 0.160..  Test Loss: 0.096..  Test Accuracy: 100.000\n",
      "Epoch: 457/500..  Train Loss: 0.215..  Test Loss: 0.097..  Test Accuracy: 100.000\n",
      "Epoch: 458/500..  Train Loss: 0.124..  Test Loss: 0.097..  Test Accuracy: 100.000\n",
      "Epoch: 459/500..  Train Loss: 0.240..  Test Loss: 0.096..  Test Accuracy: 100.000\n",
      "Epoch: 460/500..  Train Loss: 0.162..  Test Loss: 0.097..  Test Accuracy: 100.000\n",
      "Epoch: 461/500..  Train Loss: 0.204..  Test Loss: 0.098..  Test Accuracy: 100.000\n",
      "Epoch: 462/500..  Train Loss: 0.121..  Test Loss: 0.097..  Test Accuracy: 100.000\n",
      "Epoch: 463/500..  Train Loss: 0.121..  Test Loss: 0.096..  Test Accuracy: 100.000\n",
      "Epoch: 464/500..  Train Loss: 0.226..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 465/500..  Train Loss: 0.096..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 466/500..  Train Loss: 0.191..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 467/500..  Train Loss: 0.207..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 468/500..  Train Loss: 0.259..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 469/500..  Train Loss: 0.157..  Test Loss: 0.096..  Test Accuracy: 100.000\n",
      "Epoch: 470/500..  Train Loss: 0.219..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 471/500..  Train Loss: 0.216..  Test Loss: 0.096..  Test Accuracy: 100.000\n",
      "Epoch: 472/500..  Train Loss: 0.148..  Test Loss: 0.096..  Test Accuracy: 100.000\n",
      "Epoch: 473/500..  Train Loss: 0.191..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 474/500..  Train Loss: 0.203..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 475/500..  Train Loss: 0.112..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 476/500..  Train Loss: 0.233..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 477/500..  Train Loss: 0.114..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 478/500..  Train Loss: 0.143..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 479/500..  Train Loss: 0.220..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 480/500..  Train Loss: 0.103..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 481/500..  Train Loss: 0.168..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 482/500..  Train Loss: 0.198..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 483/500..  Train Loss: 0.174..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 484/500..  Train Loss: 0.181..  Test Loss: 0.092..  Test Accuracy: 100.000\n",
      "Epoch: 485/500..  Train Loss: 0.218..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 486/500..  Train Loss: 0.156..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 487/500..  Train Loss: 0.142..  Test Loss: 0.095..  Test Accuracy: 100.000\n",
      "Epoch: 488/500..  Train Loss: 0.186..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 489/500..  Train Loss: 0.111..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 490/500..  Train Loss: 0.119..  Test Loss: 0.094..  Test Accuracy: 100.000\n",
      "Epoch: 491/500..  Train Loss: 0.176..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 492/500..  Train Loss: 0.144..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 493/500..  Train Loss: 0.224..  Test Loss: 0.092..  Test Accuracy: 100.000\n",
      "Epoch: 494/500..  Train Loss: 0.107..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 495/500..  Train Loss: 0.187..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 496/500..  Train Loss: 0.131..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 497/500..  Train Loss: 0.224..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 498/500..  Train Loss: 0.180..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 499/500..  Train Loss: 0.147..  Test Loss: 0.093..  Test Accuracy: 100.000\n",
      "Epoch: 500/500..  Train Loss: 0.162..  Test Loss: 0.093..  Test Accuracy: 100.000\n"
     ]
    }
   ],
   "source": [
    "Iris_model.train(model, train_loader, test_loader, criterion, optimizer, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Iris_model_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Iris_model.Network(4, 3, [100,50])\n",
    "model.load_state_dict(torch.load(\"Iris_model_state_dict.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

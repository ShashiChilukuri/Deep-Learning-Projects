{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN(PyTorch) - CIFAR-10 database\n",
    "* Project: To classify images from CIFAR-10 database\n",
    "* Project Scope: Create, train an CNN to classify images from CIFAR-10 database\n",
    "* Data source: [CIFAR-10 Database](https://pytorch.org/docs/stable/torchvision/datasets.html). The images in this database are small color images that fall into one of ten classes\n",
    "* Author: Shashi Kiran Chilukuri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# Sample batch size to load\n",
    "batch_size = 20\n",
    "# Percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# Converting data to a normalized torch.FloatTensor\n",
    "# Performing the data augmentation to rotate or flip the given image data\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomRotation(10),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "# Getting train and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Creating indices to split train data\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# Creating training and validation sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# Creating train, validation and test loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "                                           sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
    "\n",
    "# Obtain a batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = np.squeeze(images[0])\n",
    "channels = ['red channel', 'green channel', 'blue channel']\n",
    "\n",
    "fig = plt.figure(figsize = (36, 36)) \n",
    "for idx in np.arange(rgb_img.shape[0]):\n",
    "    ax = fig.add_subplot(1, 3, idx + 1)\n",
    "    img = rgb_img[idx]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(channels[idx])\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center', size=8,\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        # Note: All Conv2d layers have a default stride of 1. Going with default         \n",
    "        ####### Output size for a convolutional layer will be calculated like this...#######\n",
    "        # W(out) = [(W(input)−F+2P)/S] + 1,    H(out)=[(H(input)−F+2P)/S] + 1 ,     D(out)=K\n",
    "        ####### Output size for a max pooling layer will be calculated like this.....#######\n",
    "        # W(Output)=[(W(input)−F)/S]+1,    H(Output)=[(H(input)−F)/S]+1,     D(output)=D(input)\n",
    "        # W,H,D are width,height and Depth,F=filter size, P=padding, S=strid, K=number of filters\n",
    "        \n",
    "        # Convolutional layer-1                     \n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1)  # input: 32X32X3, output: 32X32X16\n",
    "        # Max Pooling layer -1                      input: 32X32X16, output: 16X16X16            \n",
    "        # Convolutional layer 2                     \n",
    "        self.conv2 = nn.Conv2d(16,32,3,padding=1) # input: 16X16X16, output: 16X16X32\n",
    "        # Max Pooling layer -2                      input: 16X16X32, output: 8X8X32 \n",
    "        # Convolutional layer 3                     \n",
    "        self.conv3 = nn.Conv2d(32,64,3,padding=1) # input: 8X8X32, output: 8X8X64\n",
    "        # Max Pooling layer -3                    # input: 8X8X64, output: 4X4X64 \n",
    "            \n",
    "        # We will be using this self.pool in above 3 layers\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # Fully connected Linear layer-1 will have inputs:64*4*4 (from maxpool3) & outputs:500 nodes\n",
    "        self.fc1 = nn.Linear(64*4*4, 500)\n",
    "        # Fully connected Linear layer-2 will have inputs:64*4*4 (from maxpool3) & outputs:500 nodes\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "        \n",
    "        # We will have dropout layer (p=0.25) for each full connected layer\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Adding sequence of layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        \n",
    "        # Dropout layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Full connected layer-1 (hidden layer 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Dropout layer \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Full connected layer-1 (hidden layer 1)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "print(model)\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "# initialize minimum validation loss tracker\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for e in range(epochs):\n",
    "    # moditoring train and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()                              # Enabling the network training mode\n",
    "    for image, label in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            image, label = image.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()                  # Clearing previous gradients\n",
    "        output = model(image)                  # Forward pass: compute predicted outputs\n",
    "        loss = criterion(output,label)         # Calculating the loss\n",
    "        loss.backward()                        # Backward pass: Compute gradient of the loss\n",
    "        optimizer.step()                       # Perform single optimizer step\n",
    "        train_loss += loss.item()*image.size(0)# updating running training loss\n",
    "        \n",
    "    ######################\n",
    "    # Validate the model #\n",
    "    ######################\n",
    "    model.eval()                              # Enabling the network evaluation mode\n",
    "    for image, label in valid_loader:\n",
    "        if train_on_gpu:\n",
    "            image, label = image.cuda(), label.cuda()\n",
    "        output = model(image)                  # Forward pass: compute predicted outputs\n",
    "        loss = criterion(output,label)         # Calculating the loss\n",
    "        valid_loss += loss.item()*image.size(0)# updating running validation loss\n",
    "    \n",
    "    # Printing calculated average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    \n",
    "    print(\"Epoch: {}/{} \".format(e+1, epochs),\n",
    "          \"\\t Train Loss: {:.4f} \".format(train_loss),\n",
    "          \"\\t Valid Loss: {:.4f} \".format(valid_loss))\n",
    "    \n",
    "    # Save the model if the validation loss has descreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased from {:.4f} --> {:.4f}. SAVING THE MODEL'\n",
    "              .format(valid_loss_min,valid_loss))\n",
    "        \n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model with lowest validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Testing the model #\n",
    "#####################\n",
    "# Initializing the test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()                               # Enabling the network evaluation mode\n",
    "for image, label in train_loader:\n",
    "   \n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        image, label = image.cuda(), label.cuda()\n",
    "    \n",
    "    output = model(image)                  # Forward pass: compute predicted outputs\n",
    "    loss = criterion(output,label)         # Calculating the loss\n",
    "    test_loss += loss.item()*image.size(0) # updating running validation loss\n",
    "    \n",
    "    _, pred = torch.max(output, 1)    # Converting output probabilities to predicted class\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(label.data.view_as(pred))) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        class_correct[label.data[i]] += correct[i].item()\n",
    "        class_total[label.data[i]] += 1\n",
    "\n",
    "# Printing test accuracy for each object class\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %2s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %2s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "# Printing test loss and accuracy\n",
    "print(\"Test Loss: {:.4f} \".format(test_loss/len(test_loader.dataset)),\n",
    "      \"Test Accuracy (overall): {:.2f}% \".format(100. * np.sum(class_correct) / np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Sample test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()\n",
    "\n",
    "# move model inputs to cuda, if GPU available\n",
    "if train_on_gpu:\n",
    "    images = images.cuda()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# convert output probabilities to predicted class\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "# plot the images in the batch, along with predicted and true labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
